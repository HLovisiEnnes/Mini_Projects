{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_min = np.load(\"Temperature_min.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25551"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19163.25, 3832.6499999999996, 2555.1000000000004)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_min)*.75,len(temp_min)*.15,len(temp_min)*.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_min_train, temp_min_valid, temp_min_test = temp_min[:19163], temp_min[19163:19163+3832], temp_min[19163+3832:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19163, 3832, 2556)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_min_train), len(temp_min_valid), len(temp_min_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now break the data into windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(batch):\n",
    "    X = batch[ :, :-1] #first elements for X\n",
    "    y = batch[ :, 1:] # last elements for y\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_dataset(data, window_size=50, window_shift=25):\n",
    "    data_set = []\n",
    "    i=0\n",
    "    while window_shift*i+window_size<len(data)+1:\n",
    "        window = data[window_shift*i:window_shift*i+window_size]\n",
    "        data_set.append(np.array(window))\n",
    "        i+=1\n",
    "    shuffle(data_set)\n",
    "    return np.array(data_set).reshape(len(data_set),window_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_temp_min_train = batch_dataset(temp_min_train)\n",
    "batched_temp_min_valid = batch_dataset(temp_min_valid)\n",
    "batched_temp_min_test = batch_dataset(temp_min_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 50, 1)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_temp_min_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_target(batched_temp_min_train)\n",
    "X_valid, y_valid = create_target(batched_temp_min_valid)\n",
    "X_test, y_test = create_target(batched_temp_min_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27953088],\n",
       "       [0.72933996],\n",
       "       [1.29160131],\n",
       "       [0.84179223],\n",
       "       [1.29160131],\n",
       "       [0.84179223],\n",
       "       [0.39198315],\n",
       "       [1.29160131],\n",
       "       [1.74141039],\n",
       "       [1.17914904],\n",
       "       [0.72933996],\n",
       "       [0.50443542],\n",
       "       [0.61688769],\n",
       "       [0.27953088],\n",
       "       [0.05462634],\n",
       "       [0.16707861],\n",
       "       [0.72933996],\n",
       "       [0.61688769],\n",
       "       [0.50443542],\n",
       "       [0.72933996],\n",
       "       [0.50443542],\n",
       "       [1.06669677],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.06669677],\n",
       "       [1.29160131],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.06669677],\n",
       "       [1.29160131],\n",
       "       [1.96631494],\n",
       "       [1.62895812],\n",
       "       [1.40405358],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.29160131],\n",
       "       [1.29160131],\n",
       "       [1.51650585],\n",
       "       [1.85386266],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.40405358],\n",
       "       [1.51650585],\n",
       "       [1.06669677],\n",
       "       [1.40405358],\n",
       "       [1.40405358],\n",
       "       [1.29160131]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72933996],\n",
       "       [1.29160131],\n",
       "       [0.84179223],\n",
       "       [1.29160131],\n",
       "       [0.84179223],\n",
       "       [0.39198315],\n",
       "       [1.29160131],\n",
       "       [1.74141039],\n",
       "       [1.17914904],\n",
       "       [0.72933996],\n",
       "       [0.50443542],\n",
       "       [0.61688769],\n",
       "       [0.27953088],\n",
       "       [0.05462634],\n",
       "       [0.16707861],\n",
       "       [0.72933996],\n",
       "       [0.61688769],\n",
       "       [0.50443542],\n",
       "       [0.72933996],\n",
       "       [0.50443542],\n",
       "       [1.06669677],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.06669677],\n",
       "       [1.29160131],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.06669677],\n",
       "       [1.29160131],\n",
       "       [1.96631494],\n",
       "       [1.62895812],\n",
       "       [1.40405358],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.29160131],\n",
       "       [1.29160131],\n",
       "       [1.51650585],\n",
       "       [1.85386266],\n",
       "       [1.17914904],\n",
       "       [1.17914904],\n",
       "       [1.40405358],\n",
       "       [1.51650585],\n",
       "       [1.06669677],\n",
       "       [1.40405358],\n",
       "       [1.40405358],\n",
       "       [1.29160131],\n",
       "       [1.40405358]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((765, 49, 1), (765, 49, 1))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good! Time to train! I will start a group of convolutions,2 GRUs for long term and and output dense with no activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.GRU(20, return_sequences = True), \n",
    "    keras.layers.GRU(20, return_sequences = True), \n",
    "    keras.layers.TimeDistributed( keras.layers.Dense(1, activation = None)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( loss =\"mse\", optimizer =\"adam\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 765 samples, validate on 152 samples\n",
      "Epoch 1/1000\n",
      "765/765 [==============================] - 14s 19ms/sample - loss: 0.4199 - val_loss: 0.7865\n",
      "Epoch 2/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.2311 - val_loss: 0.7610\n",
      "Epoch 3/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.2030 - val_loss: 0.7041\n",
      "Epoch 4/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1966 - val_loss: 0.6224\n",
      "Epoch 5/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.2004 - val_loss: 0.6437\n",
      "Epoch 6/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1894 - val_loss: 0.5379\n",
      "Epoch 7/1000\n",
      "765/765 [==============================] - 4s 5ms/sample - loss: 0.1830 - val_loss: 0.5362\n",
      "Epoch 8/1000\n",
      "765/765 [==============================] - 4s 5ms/sample - loss: 0.1803 - val_loss: 0.4782\n",
      "Epoch 9/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1787 - val_loss: 0.4253\n",
      "Epoch 10/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1772 - val_loss: 0.3740\n",
      "Epoch 11/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1670 - val_loss: 0.3250\n",
      "Epoch 12/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1690 - val_loss: 0.2801\n",
      "Epoch 13/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1701 - val_loss: 0.2400\n",
      "Epoch 14/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1691 - val_loss: 0.2480\n",
      "Epoch 15/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1642 - val_loss: 0.2380\n",
      "Epoch 16/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1632 - val_loss: 0.2097\n",
      "Epoch 17/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1603 - val_loss: 0.2015\n",
      "Epoch 18/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1596 - val_loss: 0.1865\n",
      "Epoch 19/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1641 - val_loss: 0.1901\n",
      "Epoch 20/1000\n",
      "765/765 [==============================] - 4s 5ms/sample - loss: 0.1583 - val_loss: 0.1673\n",
      "Epoch 21/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1554 - val_loss: 0.1611\n",
      "Epoch 22/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1517 - val_loss: 0.1652\n",
      "Epoch 23/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1468 - val_loss: 0.1608\n",
      "Epoch 24/1000\n",
      "765/765 [==============================] - 3s 5ms/sample - loss: 0.1493 - val_loss: 0.1625\n",
      "Epoch 25/1000\n",
      "765/765 [==============================] - 4s 5ms/sample - loss: 0.1476 - val_loss: 0.1619\n",
      "Epoch 26/1000\n",
      "765/765 [==============================] - 3s 5ms/sample - loss: 0.1471 - val_loss: 0.1665\n",
      "Epoch 27/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1434 - val_loss: 0.1589\n",
      "Epoch 28/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1404 - val_loss: 0.1604\n",
      "Epoch 29/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1400 - val_loss: 0.1669\n",
      "Epoch 30/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1434 - val_loss: 0.1677\n",
      "Epoch 31/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1423 - val_loss: 0.1697\n",
      "Epoch 32/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1407 - val_loss: 0.1790\n",
      "Epoch 33/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1356 - val_loss: 0.1716\n",
      "Epoch 34/1000\n",
      "765/765 [==============================] - 3s 4ms/sample - loss: 0.1379 - val_loss: 0.1840\n",
      "Epoch 35/1000\n",
      "765/765 [==============================] - 4s 5ms/sample - loss: 0.1316 - val_loss: 0.1672\n",
      "Epoch 36/1000\n",
      "765/765 [==============================] - 4s 5ms/sample - loss: 0.1270 - val_loss: 0.1676\n",
      "Epoch 37/1000\n",
      "765/765 [==============================] - 4s 5ms/sample - loss: 0.1266 - val_loss: 0.1684\n"
     ]
    }
   ],
   "source": [
    "history = model.fit( X_train, y_train, epochs = 1000, validation_data =( X_valid, y_valid),callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 1ms/sample - loss: 0.1605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16054220143521186"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Min_Temp_pred_2\",pred)\n",
    "np.save(\"Min_Temp_y_2\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
